{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File for downloading GloVe and using it as the predictors in a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Forcing middle-class workers to bear a greater...</td>\n",
       "      <td>forcing middle class workers bear greater shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Because it would not be worthwhile to bring a ...</td>\n",
       "      <td>would worthwhile bring case arbitration clause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indeed , Lind argues that high profits and hig...</td>\n",
       "      <td>indeed lind argues high profits high wages rei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>In fairness , it should be noted that he devot...</td>\n",
       "      <td>fairness noted devotes entire chapter new york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Psychological tactics are social control techn...</td>\n",
       "      <td>psychological tactics social control technique...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                              words  \\\n",
       "0.0      0  Forcing middle-class workers to bear a greater...   \n",
       "1.0      0  Because it would not be worthwhile to bring a ...   \n",
       "2.0      0  Indeed , Lind argues that high profits and hig...   \n",
       "3.0      0  In fairness , it should be noted that he devot...   \n",
       "4.0      0  Psychological tactics are social control techn...   \n",
       "\n",
       "                                           words_clean  \n",
       "0.0  forcing middle class workers bear greater shar...  \n",
       "1.0  would worthwhile bring case arbitration clause...  \n",
       "2.0  indeed lind argues high profits high wages rei...  \n",
       "3.0  fairness noted devotes entire chapter new york...  \n",
       "4.0  psychological tactics social control technique...  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "dat = pd.read_excel('all_sentences.xlsx')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of words in corpus\n",
    "sentence = dat['words_clean'].iloc[0]\n",
    "words = sentence.split(' ')\n",
    "\n",
    "float(words.count(words[0]))/len(words)\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "for sentence in dat['words_clean']:\n",
    "    for word in sentence.split(' '):\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = sum([1 for sentence in dat['words_clean'] if word in sentence.split(' ')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "word_dict['forcing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementing IDF by hand\n",
    "idf = []\n",
    "for sentence in dat['words_clean']:   \n",
    "    word_freq = []\n",
    "    for word in sentence.split(' '):\n",
    "        word_freq.append(word_dict[word])\n",
    "    idf.append([math.log(dat.shape[0]/float(count)) for count in word_freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf_dict = {}\n",
    "for key,val in word_dict.iteritems():\n",
    "    idf_dict[key] = math.log(dat.shape[0]/float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.104048907855128"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dict['forcing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5372, (5372, 4))"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf), dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add IDF values to dataframe\n",
    "dat['idf'] = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_clean</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Forcing middle-class workers to bear a greater...</td>\n",
       "      <td>forcing middle class workers bear greater shar...</td>\n",
       "      <td>[6.10404890786, 3.93499520749, 3.62611092738, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Because it would not be worthwhile to bring a ...</td>\n",
       "      <td>would worthwhile bring case arbitration clause...</td>\n",
       "      <td>[2.38237963092, 7.20266119652, 5.45346134171, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indeed , Lind argues that high profits and hig...</td>\n",
       "      <td>indeed lind argues high profits high wages rei...</td>\n",
       "      <td>[5.12321965484, 7.89580837708, 4.71775454674, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>In fairness , it should be noted that he devot...</td>\n",
       "      <td>fairness noted devotes entire chapter new york...</td>\n",
       "      <td>[6.64304540859, 5.37007973277, 7.89580837708, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Psychological tactics are social control techn...</td>\n",
       "      <td>psychological tactics social control technique...</td>\n",
       "      <td>[6.64304540859, 6.28637046465, 3.10001783149, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                              words  \\\n",
       "0.0      0  Forcing middle-class workers to bear a greater...   \n",
       "1.0      0  Because it would not be worthwhile to bring a ...   \n",
       "2.0      0  Indeed , Lind argues that high profits and hig...   \n",
       "3.0      0  In fairness , it should be noted that he devot...   \n",
       "4.0      0  Psychological tactics are social control techn...   \n",
       "\n",
       "                                           words_clean  \\\n",
       "0.0  forcing middle class workers bear greater shar...   \n",
       "1.0  would worthwhile bring case arbitration clause...   \n",
       "2.0  indeed lind argues high profits high wages rei...   \n",
       "3.0  fairness noted devotes entire chapter new york...   \n",
       "4.0  psychological tactics social control technique...   \n",
       "\n",
       "                                                   idf  \n",
       "0.0  [6.10404890786, 3.93499520749, 3.62611092738, ...  \n",
       "1.0  [2.38237963092, 7.20266119652, 5.45346134171, ...  \n",
       "2.0  [5.12321965484, 7.89580837708, 4.71775454674, ...  \n",
       "3.0  [6.64304540859, 5.37007973277, 7.89580837708, ...  \n",
       "4.0  [6.64304540859, 6.28637046465, 3.10001783149, ...  "
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.4903432689750185, 8.588955557643128, 8.588955557643128, 7.895808377083183, 8.588955557643128, 6.797196088415073, 5.092447996176648]\n",
      "[3, 1, 1, 2, 1, 6, 33]\n",
      "[0.06382978723404255, 0.02127659574468085, 0.02127659574468085, 0.0425531914893617, 0.02127659574468085, 0.1276595744680851, 0.7021276595744681]\n"
     ]
    }
   ],
   "source": [
    "word_freq = []\n",
    "for word in sentence.split(' '):\n",
    "    word_freq.append(word_dict[word])\n",
    "    \n",
    "print [math.log(dat.shape[0]/float(count)) for count in word_freq]\n",
    "print word_freq\n",
    "print [float(count)/sum(word_freq) for count in word_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'forcing middle class workers bear greater share cost government weakens support needed investments stirs resentment toward depend public services'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['words_clean'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MIght not need all this??\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(dat['words_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4326x14764 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 92621 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4326, 14764)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(bag_of_words)\n",
    "X_train_tf = tf_transformer.transform(bag_of_words)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf[0,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Import, Testing, and Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import pretrained glove vectors\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.8523603677749634),\n",
       " (u'throne', 0.7664333581924438),\n",
       " (u'prince', 0.759214460849762),\n",
       " (u'daughter', 0.7473883032798767),\n",
       " (u'elizabeth', 0.7460220456123352)]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing vectors\n",
    "glove_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'thrilled', 0.8795695900917053),\n",
       " (u'amazed', 0.8213223218917847),\n",
       " (u'definitely', 0.8046097755432129),\n",
       " (u\"'m\", 0.802273690700531),\n",
       " (u'happy', 0.7983384132385254)]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing vectors\n",
    "glove_model.most_similar('excited', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43943   ,  0.29657999,  0.44867   ,  0.23591   ,  0.94338   ,\n",
       "        0.32563999, -0.88607001,  0.10126   , -0.49053001,  0.047319  ,\n",
       "        0.35266   ,  0.82309002, -0.72639   ,  0.47466001,  0.27928001,\n",
       "       -0.27307999,  0.55792999, -1.24950004, -0.41683999,  0.26661   ,\n",
       "        0.0283    ,  0.55105001,  0.19496   ,  0.077513  ,  0.079079  ,\n",
       "       -1.03699994,  0.57209998, -1.04229999, -1.09500003, -0.073586  ,\n",
       "        1.10239995, -0.85009998, -0.71897   , -0.66255999, -0.022977  ,\n",
       "       -0.17501999, -0.18613   ,  0.24626   ,  1.7687    , -0.016052  ,\n",
       "        0.15638   ,  1.12129998, -0.12678   , -1.13510001,  0.68115002,\n",
       "        0.74198997,  0.1877    , -1.06570005,  0.43312001,  0.24698   ], dtype=float32)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing vectors\n",
    "glove_model.wv['daniel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = glove_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create columns for avg_vec, sum_vec, and both of those weighted\n",
    "avg_vec = np.full(dat.shape[0], None)\n",
    "sum_vec = np.full(dat.shape[0], None)\n",
    "weighted_avg_vec = np.full(dat.shape[0], None)\n",
    "weighted_sum_vec = np.full(dat.shape[0], None)\n",
    "for i, sentence in enumerate(dat['words_clean']):\n",
    "    words = sentence.split(' ')\n",
    "    #print i\n",
    "    real_words = []\n",
    "    real_weights = []\n",
    "    for word in words:\n",
    "        if word in glove_model.wv:\n",
    "            real_words.append(word)\n",
    "            real_weights.append(idf_dict[word])\n",
    "            \n",
    "    vecs = np.full(len(real_words), None)\n",
    "    weighted_vecs = np.full(len(real_words), None)\n",
    "    #print words\n",
    "    for j, word in enumerate(real_words):\n",
    "        vecs[j] = glove_model.wv[word]\n",
    "        weighted_vecs[j] = glove_model.wv[word] * real_weights[j]\n",
    "    \n",
    "    weighted_sum_vec[i] = sum(weighted_vecs)\n",
    "    weighted_avg_vec[i] = sum(weighted_vecs)/float(sum(real_weights))\n",
    "    avg_vec[i] = sum(vecs)/len(vecs)\n",
    "    sum_vec[i] = sum(vecs)\n",
    "    \n",
    "dat['sum_vec'] = sum_vec\n",
    "dat['avg_vec'] = avg_vec\n",
    "dat['weighted_avg_vec'] = weighted_avg_vec\n",
    "dat['weighted_sum_vec'] = weighted_sum_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_clean</th>\n",
       "      <th>idf</th>\n",
       "      <th>sum_vec</th>\n",
       "      <th>avg_vec</th>\n",
       "      <th>weighted_avg_vec</th>\n",
       "      <th>weighted_sum_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Forcing middle-class workers to bear a greater...</td>\n",
       "      <td>forcing middle class workers bear greater shar...</td>\n",
       "      <td>[6.10404890786, 3.93499520749, 3.62611092738, ...</td>\n",
       "      <td>[4.79607, 1.69907, 5.25044, -6.22599, 2.55119,...</td>\n",
       "      <td>[0.252425, 0.0894248, 0.276339, -0.327684, 0.1...</td>\n",
       "      <td>[0.223467, 0.0817972, 0.246648, -0.305011, 0.1...</td>\n",
       "      <td>[20.6355, 7.55337, 22.7761, -28.1655, 11.0272,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Because it would not be worthwhile to bring a ...</td>\n",
       "      <td>would worthwhile bring case arbitration clause...</td>\n",
       "      <td>[2.38237963092, 7.20266119652, 5.45346134171, ...</td>\n",
       "      <td>[6.79759, -2.75716, -4.73693, -0.350068, 3.601...</td>\n",
       "      <td>[0.33988, -0.137858, -0.236846, -0.0175034, 0....</td>\n",
       "      <td>[0.30305, -0.172721, -0.297291, 0.00720224, 0....</td>\n",
       "      <td>[32.3558, -18.441, -31.7409, 0.768962, 14.779,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Indeed , Lind argues that high profits and hig...</td>\n",
       "      <td>indeed lind argues high profits high wages rei...</td>\n",
       "      <td>[5.12321965484, 7.89580837708, 4.71775454674, ...</td>\n",
       "      <td>[0.36504, -1.32171, 4.03973, -4.02884, 1.79523...</td>\n",
       "      <td>[0.02808, -0.10167, 0.310748, -0.309911, 0.138...</td>\n",
       "      <td>[0.075521, -0.154822, 0.298123, -0.273047, 0.1...</td>\n",
       "      <td>[5.07958, -10.4134, 20.0519, -18.3653, 10.9096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>In fairness , it should be noted that he devot...</td>\n",
       "      <td>fairness noted devotes entire chapter new york...</td>\n",
       "      <td>[6.64304540859, 5.37007973277, 7.89580837708, ...</td>\n",
       "      <td>[-7.31102, 8.90912, -4.11219, 0.903822, 3.9656...</td>\n",
       "      <td>[-0.332319, 0.40496, -0.186918, 0.0410828, 0.1...</td>\n",
       "      <td>[-0.353876, 0.425656, -0.194207, 0.0904033, 0....</td>\n",
       "      <td>[-45.856, 55.1575, -25.1658, 11.7147, 21.3939,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Psychological tactics are social control techn...</td>\n",
       "      <td>psychological tactics social control technique...</td>\n",
       "      <td>[6.64304540859, 6.28637046465, 3.10001783149, ...</td>\n",
       "      <td>[5.29807, -4.94703, 1.31191, -5.86548, -0.8557...</td>\n",
       "      <td>[0.33113, -0.30919, 0.0819944, -0.366592, -0.0...</td>\n",
       "      <td>[0.336981, -0.384413, 0.103796, -0.405972, -0....</td>\n",
       "      <td>[28.8706, -32.9343, 8.8926, -34.7813, -6.83236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0</td>\n",
       "      <td>The uncontrolled profit motive is destroying h...</td>\n",
       "      <td>uncontrolled profit motive destroying health i...</td>\n",
       "      <td>[7.89580837708, 4.82775544195, 6.97951764521, ...</td>\n",
       "      <td>[7.68936, -5.6458, 3.04431, -3.57051, -0.75572...</td>\n",
       "      <td>[0.54924, -0.403271, 0.217451, -0.255037, -0.0...</td>\n",
       "      <td>[0.547838, -0.485027, 0.114258, -0.208554, -0....</td>\n",
       "      <td>[45.8133, -40.5607, 9.55493, -17.4404, -3.5667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Organizations representing the religious right...</td>\n",
       "      <td>organizations representing religious right loy...</td>\n",
       "      <td>[5.29311869164, 6.97951764521, 5.15496835316, ...</td>\n",
       "      <td>[-3.04053, -1.52265, -1.02142, -5.80551, 6.230...</td>\n",
       "      <td>[-0.178855, -0.0895678, -0.0600837, -0.341501,...</td>\n",
       "      <td>[-0.297347, -0.128609, -0.128135, -0.286796, 0...</td>\n",
       "      <td>[-28.1698, -12.1841, -12.1391, -27.1702, 34.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0</td>\n",
       "      <td>A market based on greed and fear has tugged on...</td>\n",
       "      <td>market based greed fear tugged worst things us...</td>\n",
       "      <td>[3.19079285613, 3.80146381486, 5.22165972766, ...</td>\n",
       "      <td>[2.09188, -1.70208, 1.48798, -2.71342, 1.75557...</td>\n",
       "      <td>[0.209188, -0.170208, 0.148798, -0.271342, 0.1...</td>\n",
       "      <td>[0.166599, -0.212585, 0.107497, -0.374009, 0.1...</td>\n",
       "      <td>[8.01947, -10.233, 5.17453, -18.0034, 6.48401,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0</td>\n",
       "      <td>THE CONSERVATIVE MOVEMENT IS ROOTED IN A COHER...</td>\n",
       "      <td>conservative movement rooted coherent easy sum...</td>\n",
       "      <td>[4.06716698059, 4.31228943863, 6.28637046465, ...</td>\n",
       "      <td>[0.686753, 0.993661, 1.78845, -6.54942, 9.9502...</td>\n",
       "      <td>[0.0274701, 0.0397465, 0.0715382, -0.261977, 0...</td>\n",
       "      <td>[0.0532822, 0.016406, 0.0275177, -0.294374, 0....</td>\n",
       "      <td>[6.61953, 2.0382, 3.41867, -36.5716, 50.5963, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0</td>\n",
       "      <td>By eliminating the private insurer , you could...</td>\n",
       "      <td>eliminating private insurer could save billion...</td>\n",
       "      <td>[5.54443311992, 3.47696776929, 7.20266119652, ...</td>\n",
       "      <td>[12.2866, -3.33005, 12.0976, -5.19781, -1.5351...</td>\n",
       "      <td>[0.438809, -0.11893, 0.432055, -0.185636, -0.0...</td>\n",
       "      <td>[0.409654, -0.13104, 0.404075, -0.127847, -0.0...</td>\n",
       "      <td>[52.5201, -16.8002, 51.805, -16.3908, -7.03142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0</td>\n",
       "      <td>The additional schooling foisted upon one grou...</td>\n",
       "      <td>additional schooling foisted upon one group ar...</td>\n",
       "      <td>[5.88090535654, 6.64304540859, 7.89580837708, ...</td>\n",
       "      <td>[5.50139, -0.786673, 0.964377, -6.3971, 3.6078...</td>\n",
       "      <td>[0.250063, -0.0357579, 0.0438353, -0.290777, 0...</td>\n",
       "      <td>[0.243953, -0.0802103, -0.000630392, -0.330125...</td>\n",
       "      <td>[29.0081, -9.53767, -0.0749588, -39.2546, 12.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>0</td>\n",
       "      <td>If the government will do its job and prevent ...</td>\n",
       "      <td>government job prevent flood illegal immigrati...</td>\n",
       "      <td>[2.39047684115, 4.21950770518, 5.25675104747, ...</td>\n",
       "      <td>[5.56506, -3.67927, 4.74909, -8.95754, 7.78097...</td>\n",
       "      <td>[0.222602, -0.147171, 0.189964, -0.358302, 0.3...</td>\n",
       "      <td>[0.223624, -0.166096, 0.19273, -0.371718, 0.26...</td>\n",
       "      <td>[27.7451, -20.6076, 23.9122, -46.1193, 33.4712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0</td>\n",
       "      <td>The rich countries that are primarily responsi...</td>\n",
       "      <td>rich countries primarily responsible climate c...</td>\n",
       "      <td>[3.67630067191, 4.54590428981, 5.69858379975, ...</td>\n",
       "      <td>[2.4989, 3.01579, 2.35797, -0.24143, 1.87667, ...</td>\n",
       "      <td>[0.156182, 0.188487, 0.147373, -0.0150894, 0.1...</td>\n",
       "      <td>[0.158239, 0.170612, 0.156471, -0.0374894, 0.1...</td>\n",
       "      <td>[12.8648, 13.8708, 12.7211, -3.04789, 11.0346,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0</td>\n",
       "      <td>These people said to us : Well , if you just w...</td>\n",
       "      <td>people said us well would away glass steagall ...</td>\n",
       "      <td>[2.55827029738, 3.49520535684, 3.44146108083, ...</td>\n",
       "      <td>[9.27351, 1.91845, 3.36147, -5.45845, -0.16334...</td>\n",
       "      <td>[0.319776, 0.0661533, 0.115913, -0.188222, -0....</td>\n",
       "      <td>[0.222821, 0.105081, 0.00899568, -0.20268, -0....</td>\n",
       "      <td>[32.6538, 15.3992, 1.31829, -29.7022, -10.4547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Inevitably this forced them to cut some $ 270 ...</td>\n",
       "      <td>inevitably forced cut billion medicare budget ...</td>\n",
       "      <td>[6.50951401596, 4.67693255221, 3.55200295523, ...</td>\n",
       "      <td>[5.73388, 0.568736, 8.74177, -6.53144, 3.81995...</td>\n",
       "      <td>[0.358367, 0.035546, 0.546361, -0.408215, 0.23...</td>\n",
       "      <td>[0.37644, 0.110521, 0.542771, -0.363629, 0.283...</td>\n",
       "      <td>[30.1813, 8.86109, 43.5171, -29.1542, 22.6911,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hostility to taxes and open redistribution ref...</td>\n",
       "      <td>hostility taxes open redistribution reflects m...</td>\n",
       "      <td>[6.19106028484, 3.91612672318, 5.09244799618, ...</td>\n",
       "      <td>[0.18455, 4.70332, -6.94373, -6.62148, 10.8436...</td>\n",
       "      <td>[0.00738202, 0.188133, -0.277749, -0.264859, 0...</td>\n",
       "      <td>[-0.0124963, 0.111649, -0.315478, -0.306609, 0...</td>\n",
       "      <td>[-1.68124, 15.0211, -42.4439, -41.2507, 64.401...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0</td>\n",
       "      <td>I THINK the central idea in Marxism is of cour...</td>\n",
       "      <td>think central idea marxism course one contradi...</td>\n",
       "      <td>[4.5285125471, 4.80476592372, 4.78229306787, 6...</td>\n",
       "      <td>[5.84093, 7.06729, -5.939, -1.47327, 1.65729, ...</td>\n",
       "      <td>[0.253953, 0.307274, -0.258218, -0.0640552, 0....</td>\n",
       "      <td>[0.255624, 0.32061, -0.28668, -0.0366661, 0.04...</td>\n",
       "      <td>[31.9555, 40.0795, -35.8379, -4.58363, 5.18953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Baucus had played a key role in helping George...</td>\n",
       "      <td>baucus played key role helping george w bush e...</td>\n",
       "      <td>[8.58895555764, 5.64451657848, 5.09244799618, ...</td>\n",
       "      <td>[-6.4834, 4.55608, 3.43642, -5.30774, 0.926375...</td>\n",
       "      <td>[-0.240126, 0.168744, 0.127275, -0.196583, 0.0...</td>\n",
       "      <td>[-0.272378, 0.162107, 0.141001, -0.137326, -0....</td>\n",
       "      <td>[-42.0437, 25.0225, 21.7646, -21.1974, -4.5930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>0</td>\n",
       "      <td>We are not going to let working families who a...</td>\n",
       "      <td>going let working families suffering hard time...</td>\n",
       "      <td>[4.67693255221, 5.25675104747, 3.78493451291, ...</td>\n",
       "      <td>[5.10649, -1.68208, 9.42385, -5.05616, 5.14793...</td>\n",
       "      <td>[0.300382, -0.0989461, 0.554344, -0.297421, 0....</td>\n",
       "      <td>[0.31485, -0.115282, 0.569737, -0.266132, 0.27...</td>\n",
       "      <td>[26.1081, -9.55947, 47.2439, -22.0683, 23.1623...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0</td>\n",
       "      <td>Johnston shows why lowincome people using the ...</td>\n",
       "      <td>johnston shows lowincome people using earned i...</td>\n",
       "      <td>[7.20266119652, 6.02400620018, 6.79719608842, ...</td>\n",
       "      <td>[5.0544, -0.25156, 4.84367, -6.34651, 2.67953,...</td>\n",
       "      <td>[0.297318, -0.0147976, 0.284922, -0.373324, 0....</td>\n",
       "      <td>[0.32151, -0.0425633, 0.14223, -0.380117, 0.11...</td>\n",
       "      <td>[25.7485, -3.40873, 11.3906, -30.4421, 9.18546...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              words  \\\n",
       "0.0       0  Forcing middle-class workers to bear a greater...   \n",
       "1.0       0  Because it would not be worthwhile to bring a ...   \n",
       "2.0       0  Indeed , Lind argues that high profits and hig...   \n",
       "3.0       0  In fairness , it should be noted that he devot...   \n",
       "4.0       0  Psychological tactics are social control techn...   \n",
       "5.0       0  The uncontrolled profit motive is destroying h...   \n",
       "6.0       0  Organizations representing the religious right...   \n",
       "7.0       0  A market based on greed and fear has tugged on...   \n",
       "8.0       0  THE CONSERVATIVE MOVEMENT IS ROOTED IN A COHER...   \n",
       "9.0       0  By eliminating the private insurer , you could...   \n",
       "10.0      0  The additional schooling foisted upon one grou...   \n",
       "11.0      0  If the government will do its job and prevent ...   \n",
       "12.0      0  The rich countries that are primarily responsi...   \n",
       "13.0      0  These people said to us : Well , if you just w...   \n",
       "14.0      0  Inevitably this forced them to cut some $ 270 ...   \n",
       "15.0      0  Hostility to taxes and open redistribution ref...   \n",
       "16.0      0  I THINK the central idea in Marxism is of cour...   \n",
       "17.0      0  Baucus had played a key role in helping George...   \n",
       "18.0      0  We are not going to let working families who a...   \n",
       "19.0      0  Johnston shows why lowincome people using the ...   \n",
       "\n",
       "                                            words_clean  \\\n",
       "0.0   forcing middle class workers bear greater shar...   \n",
       "1.0   would worthwhile bring case arbitration clause...   \n",
       "2.0   indeed lind argues high profits high wages rei...   \n",
       "3.0   fairness noted devotes entire chapter new york...   \n",
       "4.0   psychological tactics social control technique...   \n",
       "5.0   uncontrolled profit motive destroying health i...   \n",
       "6.0   organizations representing religious right loy...   \n",
       "7.0   market based greed fear tugged worst things us...   \n",
       "8.0   conservative movement rooted coherent easy sum...   \n",
       "9.0   eliminating private insurer could save billion...   \n",
       "10.0  additional schooling foisted upon one group ar...   \n",
       "11.0  government job prevent flood illegal immigrati...   \n",
       "12.0  rich countries primarily responsible climate c...   \n",
       "13.0  people said us well would away glass steagall ...   \n",
       "14.0  inevitably forced cut billion medicare budget ...   \n",
       "15.0  hostility taxes open redistribution reflects m...   \n",
       "16.0  think central idea marxism course one contradi...   \n",
       "17.0  baucus played key role helping george w bush e...   \n",
       "18.0  going let working families suffering hard time...   \n",
       "19.0  johnston shows lowincome people using earned i...   \n",
       "\n",
       "                                                    idf  \\\n",
       "0.0   [6.10404890786, 3.93499520749, 3.62611092738, ...   \n",
       "1.0   [2.38237963092, 7.20266119652, 5.45346134171, ...   \n",
       "2.0   [5.12321965484, 7.89580837708, 4.71775454674, ...   \n",
       "3.0   [6.64304540859, 5.37007973277, 7.89580837708, ...   \n",
       "4.0   [6.64304540859, 6.28637046465, 3.10001783149, ...   \n",
       "5.0   [7.89580837708, 4.82775544195, 6.97951764521, ...   \n",
       "6.0   [5.29311869164, 6.97951764521, 5.15496835316, ...   \n",
       "7.0   [3.19079285613, 3.80146381486, 5.22165972766, ...   \n",
       "8.0   [4.06716698059, 4.31228943863, 6.28637046465, ...   \n",
       "9.0   [5.54443311992, 3.47696776929, 7.20266119652, ...   \n",
       "10.0  [5.88090535654, 6.64304540859, 7.89580837708, ...   \n",
       "11.0  [2.39047684115, 4.21950770518, 5.25675104747, ...   \n",
       "12.0  [3.67630067191, 4.54590428981, 5.69858379975, ...   \n",
       "13.0  [2.55827029738, 3.49520535684, 3.44146108083, ...   \n",
       "14.0  [6.50951401596, 4.67693255221, 3.55200295523, ...   \n",
       "15.0  [6.19106028484, 3.91612672318, 5.09244799618, ...   \n",
       "16.0  [4.5285125471, 4.80476592372, 4.78229306787, 6...   \n",
       "17.0  [8.58895555764, 5.64451657848, 5.09244799618, ...   \n",
       "18.0  [4.67693255221, 5.25675104747, 3.78493451291, ...   \n",
       "19.0  [7.20266119652, 6.02400620018, 6.79719608842, ...   \n",
       "\n",
       "                                                sum_vec  \\\n",
       "0.0   [4.79607, 1.69907, 5.25044, -6.22599, 2.55119,...   \n",
       "1.0   [6.79759, -2.75716, -4.73693, -0.350068, 3.601...   \n",
       "2.0   [0.36504, -1.32171, 4.03973, -4.02884, 1.79523...   \n",
       "3.0   [-7.31102, 8.90912, -4.11219, 0.903822, 3.9656...   \n",
       "4.0   [5.29807, -4.94703, 1.31191, -5.86548, -0.8557...   \n",
       "5.0   [7.68936, -5.6458, 3.04431, -3.57051, -0.75572...   \n",
       "6.0   [-3.04053, -1.52265, -1.02142, -5.80551, 6.230...   \n",
       "7.0   [2.09188, -1.70208, 1.48798, -2.71342, 1.75557...   \n",
       "8.0   [0.686753, 0.993661, 1.78845, -6.54942, 9.9502...   \n",
       "9.0   [12.2866, -3.33005, 12.0976, -5.19781, -1.5351...   \n",
       "10.0  [5.50139, -0.786673, 0.964377, -6.3971, 3.6078...   \n",
       "11.0  [5.56506, -3.67927, 4.74909, -8.95754, 7.78097...   \n",
       "12.0  [2.4989, 3.01579, 2.35797, -0.24143, 1.87667, ...   \n",
       "13.0  [9.27351, 1.91845, 3.36147, -5.45845, -0.16334...   \n",
       "14.0  [5.73388, 0.568736, 8.74177, -6.53144, 3.81995...   \n",
       "15.0  [0.18455, 4.70332, -6.94373, -6.62148, 10.8436...   \n",
       "16.0  [5.84093, 7.06729, -5.939, -1.47327, 1.65729, ...   \n",
       "17.0  [-6.4834, 4.55608, 3.43642, -5.30774, 0.926375...   \n",
       "18.0  [5.10649, -1.68208, 9.42385, -5.05616, 5.14793...   \n",
       "19.0  [5.0544, -0.25156, 4.84367, -6.34651, 2.67953,...   \n",
       "\n",
       "                                                avg_vec  \\\n",
       "0.0   [0.252425, 0.0894248, 0.276339, -0.327684, 0.1...   \n",
       "1.0   [0.33988, -0.137858, -0.236846, -0.0175034, 0....   \n",
       "2.0   [0.02808, -0.10167, 0.310748, -0.309911, 0.138...   \n",
       "3.0   [-0.332319, 0.40496, -0.186918, 0.0410828, 0.1...   \n",
       "4.0   [0.33113, -0.30919, 0.0819944, -0.366592, -0.0...   \n",
       "5.0   [0.54924, -0.403271, 0.217451, -0.255037, -0.0...   \n",
       "6.0   [-0.178855, -0.0895678, -0.0600837, -0.341501,...   \n",
       "7.0   [0.209188, -0.170208, 0.148798, -0.271342, 0.1...   \n",
       "8.0   [0.0274701, 0.0397465, 0.0715382, -0.261977, 0...   \n",
       "9.0   [0.438809, -0.11893, 0.432055, -0.185636, -0.0...   \n",
       "10.0  [0.250063, -0.0357579, 0.0438353, -0.290777, 0...   \n",
       "11.0  [0.222602, -0.147171, 0.189964, -0.358302, 0.3...   \n",
       "12.0  [0.156182, 0.188487, 0.147373, -0.0150894, 0.1...   \n",
       "13.0  [0.319776, 0.0661533, 0.115913, -0.188222, -0....   \n",
       "14.0  [0.358367, 0.035546, 0.546361, -0.408215, 0.23...   \n",
       "15.0  [0.00738202, 0.188133, -0.277749, -0.264859, 0...   \n",
       "16.0  [0.253953, 0.307274, -0.258218, -0.0640552, 0....   \n",
       "17.0  [-0.240126, 0.168744, 0.127275, -0.196583, 0.0...   \n",
       "18.0  [0.300382, -0.0989461, 0.554344, -0.297421, 0....   \n",
       "19.0  [0.297318, -0.0147976, 0.284922, -0.373324, 0....   \n",
       "\n",
       "                                       weighted_avg_vec  \\\n",
       "0.0   [0.223467, 0.0817972, 0.246648, -0.305011, 0.1...   \n",
       "1.0   [0.30305, -0.172721, -0.297291, 0.00720224, 0....   \n",
       "2.0   [0.075521, -0.154822, 0.298123, -0.273047, 0.1...   \n",
       "3.0   [-0.353876, 0.425656, -0.194207, 0.0904033, 0....   \n",
       "4.0   [0.336981, -0.384413, 0.103796, -0.405972, -0....   \n",
       "5.0   [0.547838, -0.485027, 0.114258, -0.208554, -0....   \n",
       "6.0   [-0.297347, -0.128609, -0.128135, -0.286796, 0...   \n",
       "7.0   [0.166599, -0.212585, 0.107497, -0.374009, 0.1...   \n",
       "8.0   [0.0532822, 0.016406, 0.0275177, -0.294374, 0....   \n",
       "9.0   [0.409654, -0.13104, 0.404075, -0.127847, -0.0...   \n",
       "10.0  [0.243953, -0.0802103, -0.000630392, -0.330125...   \n",
       "11.0  [0.223624, -0.166096, 0.19273, -0.371718, 0.26...   \n",
       "12.0  [0.158239, 0.170612, 0.156471, -0.0374894, 0.1...   \n",
       "13.0  [0.222821, 0.105081, 0.00899568, -0.20268, -0....   \n",
       "14.0  [0.37644, 0.110521, 0.542771, -0.363629, 0.283...   \n",
       "15.0  [-0.0124963, 0.111649, -0.315478, -0.306609, 0...   \n",
       "16.0  [0.255624, 0.32061, -0.28668, -0.0366661, 0.04...   \n",
       "17.0  [-0.272378, 0.162107, 0.141001, -0.137326, -0....   \n",
       "18.0  [0.31485, -0.115282, 0.569737, -0.266132, 0.27...   \n",
       "19.0  [0.32151, -0.0425633, 0.14223, -0.380117, 0.11...   \n",
       "\n",
       "                                       weighted_sum_vec  \n",
       "0.0   [20.6355, 7.55337, 22.7761, -28.1655, 11.0272,...  \n",
       "1.0   [32.3558, -18.441, -31.7409, 0.768962, 14.779,...  \n",
       "2.0   [5.07958, -10.4134, 20.0519, -18.3653, 10.9096...  \n",
       "3.0   [-45.856, 55.1575, -25.1658, 11.7147, 21.3939,...  \n",
       "4.0   [28.8706, -32.9343, 8.8926, -34.7813, -6.83236...  \n",
       "5.0   [45.8133, -40.5607, 9.55493, -17.4404, -3.5667...  \n",
       "6.0   [-28.1698, -12.1841, -12.1391, -27.1702, 34.22...  \n",
       "7.0   [8.01947, -10.233, 5.17453, -18.0034, 6.48401,...  \n",
       "8.0   [6.61953, 2.0382, 3.41867, -36.5716, 50.5963, ...  \n",
       "9.0   [52.5201, -16.8002, 51.805, -16.3908, -7.03142...  \n",
       "10.0  [29.0081, -9.53767, -0.0749588, -39.2546, 12.3...  \n",
       "11.0  [27.7451, -20.6076, 23.9122, -46.1193, 33.4712...  \n",
       "12.0  [12.8648, 13.8708, 12.7211, -3.04789, 11.0346,...  \n",
       "13.0  [32.6538, 15.3992, 1.31829, -29.7022, -10.4547...  \n",
       "14.0  [30.1813, 8.86109, 43.5171, -29.1542, 22.6911,...  \n",
       "15.0  [-1.68124, 15.0211, -42.4439, -41.2507, 64.401...  \n",
       "16.0  [31.9555, 40.0795, -35.8379, -4.58363, 5.18953...  \n",
       "17.0  [-42.0437, 25.0225, 21.7646, -21.1974, -4.5930...  \n",
       "18.0  [26.1081, -9.55947, 47.2439, -22.0683, 23.1623...  \n",
       "19.0  [25.7485, -3.40873, 11.3906, -30.4421, 9.18546...  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat['idf'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat['avg_vec'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export\n",
    "dat.to_excel('dat_large.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dat['sum_vec'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_acc(probs, y_test, thresh):\n",
    "    y_pred = []\n",
    "    for row in probs:\n",
    "        if row[1] > thresh:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(np.argmax(row))\n",
    "    #print(len(y_pred), len(y_test))\n",
    "    return y_pred, np.mean(np.array(y_pred) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14849768875192607, 0.14872881355932205, 0.1725346687211094, 0.17388289676425267, 0.21024653312788905, 0.21209553158705702, 0.26163328197226504, 0.26467642526964563, 0.31336671802773497, 0.31660246533127884, 0.36255778120184906, 0.36529275808936823, 0.40300462249614794, 0.40527734976887525, 0.43859784283513098, 0.44029275808936819, 0.46440677966101684, 0.46548536209553165, 0.4833975346687211, 0.48470724191063175, 0.49637904468412941, 0.49734206471494613, 0.50496918335901397, 0.50516178736517714, 0.50974576271186434, 0.5096687211093992, 0.51132511556240368, 0.51190292758089373, 0.51228813559322028, 0.51248073959938378, 0.51251926040061635, 0.51248073959938356, 0.51136363636363624, 0.51155624036979963, 0.51059322033898313, 0.51067026194144849, 0.51028505392912182, 0.51036209553158707, 0.51070878274268106, 0.51086286594761166, 0.51097842835130969, 0.51097842835130969, 0.51086286594761166, 0.51086286594761166, 0.51090138674884433, 0.51090138674884433, 0.51113251155624018, 0.51113251155624018, 0.51117103235747297, 0.51117103235747297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning neutral threshold\n",
    "accuracy = [0]*50\n",
    "for j in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dat['weighted_avg_vec'], dat['label'], test_size=0.3, random_state=j)\n",
    "    X_train_mat = np.matrix(X_train.values.tolist())\n",
    "    X_test_mat = np.matrix(X_test.values.tolist())\n",
    "    rf_model = ensemble.RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "    rf_model.fit(X_train_mat, y_train) \n",
    "    threshes = np.arange(0.0, 0.5, 0.01)\n",
    "    for i, thresh in enumerate(threshes):\n",
    "        probs = rf_model.predict_proba(X_test_mat)\n",
    "        accuracy[i] += return_acc(probs, y_test, thresh)[1]\n",
    "\n",
    "new_acc = [acc/20 for acc in accuracy]\n",
    "print(new_acc)\n",
    "np.argmax(new_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning max_depth\n",
    "depths = [1,2,3,5,10,30,50,70,100,200,300,500,800,1000,1500]\n",
    "avg_acc = [None]*len(depths)\n",
    "for i, depth in enumerate(depths):\n",
    "    accuracy = [0]*20\n",
    "    for j in range(len(accuracy)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dat['avg_vec'], dat['label'], test_size=0.3, random_state=j)\n",
    "        X_train_mat = np.matrix(X_train.values.tolist())\n",
    "        X_test_mat = np.matrix(X_test.values.tolist())\n",
    "        rf_model = ensemble.RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "        rf_model.fit(X_train_mat, y_train) \n",
    "        probs = rf_model.predict_proba(X_test_mat)\n",
    "        accuracy[j] += return_acc(probs, y_test, 0.30)[1]\n",
    "    avg_acc[i] = sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47214946070878272, 0.48328197226502312, 0.49345146379044691, 0.50358243451463802, 0.51409861325115569, 0.50651001540832064, 0.50878274268104784, 0.5098228043143298, 0.50531587057010785, 0.51086286594761177, 0.51197996918335886, 0.513251155624037, 0.50805084745762719, 0.50354391371340523, 0.51078582434514641]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50531587057010785"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_acc)\n",
    "np.argmax(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50372208436724564"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat['weighted_avg_vec'], dat['label'], test_size=0.3, random_state=j)\n",
    "X_train_mat = np.matrix(X_train.values.tolist())\n",
    "X_test_mat = np.matrix(X_test.values.tolist())\n",
    "rf_model = ensemble.RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "rf_model.fit(X_train_mat, y_train) \n",
    "probs = rf_model.predict_proba(X_test_mat)\n",
    "return_acc(probs, y_test, 0.30)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functionalize to see which variable is best\n",
    "def random_forest(var):\n",
    "    accuracy = [0]*20\n",
    "    for j in range(len(accuracy)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dat['avg_vec'], dat['label'], test_size=0.3, random_state=j)\n",
    "        X_train_mat = np.matrix(X_train.values.tolist())\n",
    "        X_test_mat = np.matrix(X_test.values.tolist())\n",
    "        rf_model = ensemble.RandomForestClassifier(max_depth=200, n_estimators=50)\n",
    "        rf_model.fit(X_train_mat, y_train) \n",
    "        probs = rf_model.predict_proba(X_test_mat)\n",
    "        accuracy[j] += return_acc(probs, y_test, 0.30)[1]\n",
    "    return sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535763027295\n",
      "0.537034739454\n",
      "0.537189826303\n",
      "0.536910669975\n"
     ]
    }
   ],
   "source": [
    "print random_forest('avg_vec')\n",
    "print random_forest('sum_vec')\n",
    "print random_forest('weighted_avg_vec')\n",
    "print random_forest('weighted_sum_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All forms of the vector get the same score pretty much, none outperform Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
