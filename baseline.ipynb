{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import treeUtil\n",
    "import cPickle\n",
    "from math import log\n",
    "\n",
    "\n",
    "[lib, con, neutral] = cPickle.load(open('ibcData.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSampleSize = 0.7\n",
    "libTrainDelim = int(len(lib) * trainSampleSize)\n",
    "conTrainDelim = int(len(con) * trainSampleSize)\n",
    "neutralTrainDelim = int(len(neutral) * trainSampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 180\n"
     ]
    }
   ],
   "source": [
    "neutralTestEnd = len(neutral) - neutralTrainDelim\n",
    "\n",
    "print neutralTrainDelim, neutralTestEnd\n",
    "\n",
    "libTrain = lib[0:neutralTrainDelim]\n",
    "libTest = lib[neutralTrainDelim: len(neutral)]\n",
    "\n",
    "conTrain = con[0:neutralTrainDelim]\n",
    "conTest = con[neutralTrainDelim: len(neutral)]\n",
    "\n",
    "neutralTrain = neutral[0:neutralTrainDelim]\n",
    "neutralTest = neutral[neutralTrainDelim: len(neutral)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438888888889\n"
     ]
    }
   ],
   "source": [
    "wordDict = {}\n",
    "nrated = [0] * 3\n",
    "counts = [[]]\n",
    "qFirst4([libTrain, conTrain, neutralTrain])\n",
    "counts = [ [0] * len(wordDict) for _ in range(3)]\n",
    "qSecond4([libTrain, conTrain, neutralTrain])\n",
    "\n",
    "F = [ [0] * len(wordDict) for _ in range(3)]\n",
    "q5()\n",
    "\n",
    "preds, accuracy = q6([libTest, conTest, neutralTest])\n",
    "print accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qFirst4(trainSet):\n",
    "    leanings = trainSet\n",
    "    for leaning in leanings:\n",
    "        for tree in leaning:\n",
    "            for word in tree.get_words().split(\" \"):\n",
    "                word = word.replace(\"\\n\", \"\")\n",
    "                wordDict[word] = wordDict.get(word, len(wordDict))\n",
    "\n",
    "\n",
    "def qSecond4(trainSet):\n",
    "    \"\"\"\n",
    "    You'll notice that actual words didn't appear in the last question.\n",
    "    Array indices are nicer to work with than words, so we typically\n",
    "    write a dictionary encoding the words as numbers. This turns\n",
    "    review strings into lists of integers. You will count the occurrences\n",
    "    of each integer in reviews of each class.\n",
    "    The infile has one review per line, starting with the rating and then a space.\n",
    "    Note that the \"words\" include things like punctuation and numbers. Don't worry\n",
    "    about this distinction for now; any string that occurs between spaces is a word.\n",
    "    You must do three things in this question: build the dictionary,\n",
    "    count the occurrences of each word in each rating and count the number\n",
    "    of reviews with each rating.\n",
    "    The words should be numbered sequentially in the order they first appear.\n",
    "    counts[ranking][word] is the number of times word appears in any of the\n",
    "    reviews corresponding to ranking\n",
    "    nrated[ranking] is the total number of reviews with each ranking\n",
    "    \"\"\"\n",
    "#     leanings = trainSet\n",
    "#     for leaning in leanings:\n",
    "#         for tree in leaning:\n",
    "#             for word in tree.get_words().split(\" \"):\n",
    "#                 word = word.replace(\"\\n\", \"\")\n",
    "#                 wordDict[word] = wordDict.get(word, len(wordDict))\n",
    "\n",
    "#     nrated = [0] * 3\n",
    "    leanings = trainSet\n",
    "\n",
    "    for i, leaning in enumerate(leanings):\n",
    "        for tree in leaning:\n",
    "            nrated[i] += 1\n",
    "            for word in tree.get_words().split(\" \"):\n",
    "                word = word.replace(\"\\n\", \"\")\n",
    "                counts[i][wordDict[word]] += 1\n",
    "            \n",
    "    \n",
    "\n",
    "def q5(alpha=1):\n",
    "    \"\"\"\n",
    "    Now you'll fit the model. For historical reasons, we'll call it F.\n",
    "    F[rating][word] is -log(p(word|rating)).\n",
    "    The ratings run from 0-4 to match array indexing.\n",
    "    Alpha is the per-word \"strength\" of the prior (as in q2).\n",
    "    (What might \"fairness\" mean here?)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "#     F = [ [0] * len(wordDict) for _ in range(3)]\n",
    "    for ratingIndex, ratingCount in enumerate(counts):\n",
    "        summedCount = sum(ratingCount) + (alpha * len(wordDict))\n",
    "        for wordIndex, wordCount in enumerate(ratingCount):\n",
    "            prob = (wordCount + alpha) / float(summedCount)\n",
    "            F[ratingIndex][wordIndex] = -log(prob+0.0000000000001)\n",
    "\n",
    "\n",
    "def q6(testSet):\n",
    "    \"\"\"\n",
    "    Test time! The infile has the same format as it did before. For each review,\n",
    "    predict the rating. Ignore words that don't appear in your dictionary.\n",
    "    Are there any factors that won't affect your prediction?\n",
    "    You'll report both the list of predicted ratings in order and the accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    predictions = []\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for leaningIndex, leaning in enumerate(testSet):\n",
    "        for review in leaning:\n",
    "            priorList = [-log(x / float(sum(nrated))) for x in nrated]\n",
    "            for word in review.get_words().split(\" \"):\n",
    "                if word in wordDict:\n",
    "                    for ratingIndex in range(3):\n",
    "                        priorList[ratingIndex] += F[ratingIndex][wordDict[word]]\n",
    "            bestPrediction = 0\n",
    "            minVal = float(\"inf\")\n",
    "            for i in range(len(priorList)):\n",
    "                if priorList[i] <= minVal:\n",
    "                    minVal = priorList[i]\n",
    "                    bestPrediction = i\n",
    "            count += 1\n",
    "#             print bestPrediction, leaningIndex\n",
    "            if bestPrediction == leaningIndex:\n",
    "                correct += 1\n",
    "            predictions.append(bestPrediction)\n",
    "        \n",
    "    return (predictions, correct / float(count))\n",
    "\n",
    "\n",
    "def q7():\n",
    "    \"\"\"\n",
    "    Alpha (q5) is a hyperparameter of this model - a tunable option that affects\n",
    "    the values that appear in F. Let's tune it!\n",
    "    We've split the dataset into 3 parts: the training set you use to fit the model\n",
    "    the validation and test sets you use to evaluate the model. The training set\n",
    "    is used to optimize the regular parameters, and the validation set is used to\n",
    "    optimize the hyperparameters. (Why don't you want to set the hyperparameters\n",
    "    using the test set accuracy?)\n",
    "    Find and return a good value of alpha (hint: you will want to call q5 and q6).\n",
    "    What happens when alpha = 0?\n",
    "    \"\"\"\n",
    "\n",
    "    bestAlpha = 0\n",
    "    bestAccuracy = 0\n",
    "    for alpha in [x * 0.1 for x in range(0, 20)]:\n",
    "        q5(alpha)\n",
    "        _, accuracy = q6(infile)\n",
    "        if accuracy >= bestAccuracy:\n",
    "            bestAlpha = alpha\n",
    "            bestAccuracy = accuracy\n",
    "    return bestAlpha\n",
    "\n",
    "def q8():\n",
    "    \"\"\"\n",
    "    We can also \"hallucinate\" reviews for each rating. They won't make sense\n",
    "    without a language model (for which you'll have to take CS287), but we can\n",
    "    list the 3 most representative words for each class. Representative here\n",
    "    means that the marginal information it provides (the minimal difference between\n",
    "    F[rating][word] and F[rating'][word] across all rating' != rating) is maximal.\n",
    "    You'll return the strings rather than the indices, and in decreasing order of\n",
    "    representativeness.\n",
    "    \"\"\"\n",
    "    representatives = []\n",
    "    for rating in range(3):\n",
    "        wordList = []\n",
    "        for word in wordDict:\n",
    "            maxDiff = -111000\n",
    "            for rPrime in range(3):\n",
    "                if rating != rPrime:\n",
    "                    diff = F[rating][wordDict[word]] - F[rPrime][wordDict[word]]\n",
    "                    maxDiff = max(maxDiff, diff)\n",
    "            wordList.append((maxDiff, word))\n",
    "        sortedLst = sorted(wordList, key = lambda x: x[0])\n",
    "        representatives.append([sortedLst[i][1] for i in range(3)])\n",
    "    return representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
